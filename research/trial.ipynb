{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chainlit as cl\n",
    "from llama_index.core import (VectorStoreIndex, SimpleDirectoryReader, SimpleKeywordTableIndex, Settings,\n",
    "                              StorageContext, QueryBundle, get_response_synthesizer)\n",
    "from llama_index.core.retrievers import BaseRetriever, KeywordTableSimpleRetriever, VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.llms.openai import OpenAI, AsyncOpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import os, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENAI_API_KEY=os.getenv('OPENAI_API_KEY')\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/final_data.json', 'r') as file:\n",
    "  data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, val in enumerate(data):\n",
    "  temp_data = [val]\n",
    "  with open(f'../Data1/final_data_{i}.json', 'w') as file:\n",
    "    json.dump(temp_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = SimpleDirectoryReader(\"../Data1\")\n",
    "documents = loader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.chunk_size = 200\n",
    "Settings.chunk_overlap = 50\n",
    "Settings.llm = OpenAI(model = \"gpt-3.5-turbo\")\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")\n",
    "nodes = Settings.node_parser.get_nodes_from_documents(documents=documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_context = StorageContext.from_defaults()\n",
    "storage_context.docstore.add_documents(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-19 12:44:51 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-19 12:44:55 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-19 12:44:58 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-19 12:45:01 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-19 12:45:04 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-19 12:45:07 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "vector_index = VectorStoreIndex(nodes, storage_context=storage_context)\n",
    "keyword_index = SimpleKeywordTableIndex(nodes, storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_Retriever(BaseRetriever):\n",
    "  def __init__(self, vector_retriever: VectorIndexRetriever,\n",
    "               keyword_retriever: KeywordTableSimpleRetriever, mode: str = \"AND\"):\n",
    "    self.vector_retriever = vector_retriever\n",
    "    self.keyword_retriever = keyword_retriever\n",
    "    self.mode = mode\n",
    "    super().__init__()\n",
    "\n",
    "  def _retrieve(self, query_bundle: QueryBundle):\n",
    "    vector_nodes = self.vector_retriever.retrieve(query_bundle)\n",
    "    keyword_nodes = self.keyword_retriever.retrieve(query_bundle)\n",
    "\n",
    "    vector_ids = {n.node.node_id for n in vector_nodes}\n",
    "    keyword_ids = {n.node.node_id for n in keyword_nodes}\n",
    "\n",
    "    combine_dict = {n.node.node_id: n for n in vector_nodes}\n",
    "    combine_dict.update({n.node.node_id: n for n in keyword_nodes})\n",
    "\n",
    "    if self.mode == \"AND\":\n",
    "      retrieve_ids = vector_ids.intersection(keyword_ids)\n",
    "    else:\n",
    "      retrieve_ids = vector_ids.union(keyword_ids)\n",
    "\n",
    "    retrieve_nodes = [combine_dict[rid] for rid in retrieve_ids]\n",
    "    return retrieve_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_retriever = VectorIndexRetriever(index=vector_index, similarity_top_k=3)\n",
    "keyword_retriever = KeywordTableSimpleRetriever(index=keyword_index)\n",
    "custom_retriever = Custom_Retriever(vector_retriever, keyword_retriever)\n",
    "\n",
    "response_synthesizer = get_response_synthesizer(streaming=True)\n",
    "\n",
    "custom_query_engine = RetrieverQueryEngine.from_args(retriever=custom_retriever,\n",
    "                                           response_synthesizer=response_synthesizer, streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-16 20:05:39 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-16 20:05:39 - > Starting query: How to configure Company in ITSM\n",
      "2024-05-16 20:05:39 - query keywords: ['company', 'itsm', 'configure']\n",
      "2024-05-16 20:05:39 - > Extracted keywords: ['company', 'itsm', 'configure']\n",
      "2024-05-16 20:05:40 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "response = custom_query_engine.query(\"How to configure Company in ITSM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-19 12:45:42 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-05-19 12:45:43 - > Starting query: How to configure BPMS Interface in ITSM?\n",
      "2024-05-19 12:45:43 - query keywords: ['itsm', 'interface', 'bpms', 'configure']\n",
      "2024-05-19 12:45:43 - > Extracted keywords: ['itsm', 'interface', 'bpms', 'configure']\n",
      "2024-05-19 12:45:43 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "To configure the BPMS Interface in ITSM, you need to enable the ITSM-BPMS interface from the Eric:CustomerInterface form. For the inbound flow, make sure to select the checkbox under Automation categories for Create and Update Change/Problem. This configuration will allow BPMS to create and update Change Requests and Problems for specified customers. For the outbound flow from ITSM to BPMS, ensure the necessary configuration is in place under Eric:CustomerInterface to enable ITSM to send Create CR requests and Update CR requests for specified customers towards BPMS.\n"
     ]
    }
   ],
   "source": [
    "response = custom_query_engine.query(\"How to configure BPMS Interface in ITSM?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in response.response_gen:\n",
    "    print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chainlit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
